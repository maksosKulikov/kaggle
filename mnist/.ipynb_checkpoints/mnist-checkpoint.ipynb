{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9e759e4-dd6e-4780-9a54-4c52496687fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "size = 28\n",
    "batch_size = 20\n",
    "train_size = 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe136b",
   "metadata": {},
   "source": [
    "### Данные представлены в виде таблицы, а не фоток, поэтому мне нужно будет их преобразовать сначала в изображения, а потом уже сделать аугментацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42451109-98e8-4d1b-8abb-5f6af910fdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000 28000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "print(len(df_train), len(df_test))\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "59100260-cfda-43a2-ad4d-ddb8a340a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = np.array(df_train[\"label\"])\n",
    "df_train = df_train.drop(\"label\", axis=1)\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "63514178-67ff-457d-85fc-b7238da0ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train).reshape(42000, 1, size, size)\n",
    "X_test = np.array(df_test).reshape(28000, 1, size, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "113e6a83-08aa-4b2a-8073-df5f8c3bf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid = torch.utils.data.random_split(X_train, [0.9, 0.1], generator=torch.Generator().manual_seed(1))\n",
    "Y_train, Y_valid = torch.utils.data.random_split(Y_train, [0.9, 0.1], generator=torch.Generator().manual_seed(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd80f26d-8a38-473f-9a55-446e32957326",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM = transforms.Compose([transforms.Resize(size),\n",
    "                                transforms.ToTensor()])\n",
    "\n",
    "TRANSFORM_AU = transforms.Compose([transforms.Resize(int(1.1 *size)),\n",
    "                                   transforms.RandomRotation(20),\n",
    "                                   transforms.RandomCrop(size),\n",
    "                                   transforms.ToTensor()])\n",
    "def get_data(data_numpy, need_au=False):\n",
    "    answer_arr = []\n",
    "    answer_arr.append(TRANSFORM(Image.fromarray((data_numpy).astype('uint8'))))\n",
    "    if need_au:\n",
    "        for i in range(5):\n",
    "            answer_arr.append(TRANSFORM_AU(Image.fromarray((data_numpy).astype('uint8'))))\n",
    "    return answer_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f21595b2-f12c-49e8-a93e-6e9f1955bece",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train, new_Y_train = [], []\n",
    "for i in range(len(X_train)): \n",
    "    new_data = get_data(X_train[i][0], need_au=True)\n",
    "    for item in new_data:\n",
    "        new_X_train.append(item)\n",
    "        new_Y_train.append(torch.tensor(Y_train[i]))\n",
    "train_data = TensorDataset(torch.stack(new_X_train), torch.stack(new_Y_train))\n",
    "\n",
    "new_X_valid, new_Y_valid = [], []\n",
    "for i in range(len(X_valid)): \n",
    "    new_data = get_data(X_valid[i][0], need_au=False)\n",
    "    for item in new_data:\n",
    "        new_X_valid.append(item)\n",
    "        new_Y_valid.append(torch.tensor(Y_valid[i]))\n",
    "        \n",
    "valid_data = TensorDataset(torch.stack(new_X_valid), torch.stack(new_Y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a2f039",
   "metadata": {},
   "source": [
    "### Сделал аугментацию. Сделал train и valid выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "652d550a-28c9-40c4-9273-8b86944aa289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во батчей train = 3190\n",
      "Кол-во батчей valid = 60\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=64, shuffle=True)\n",
    "\n",
    "print(\"Кол-во батчей train =\", len(train_loader))\n",
    "print(\"Кол-во батчей valid =\", len(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "479d8ef2-4dac-4893-a51d-ee181c1ad504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_net, self).__init__()\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.BatchNorm2d(32), nn.Dropout2d(0.4))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), nn.BatchNorm2d(64), nn.Dropout2d(0.4))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(7 * 7 * 64, 512),\n",
    "            nn.ReLU(), nn.BatchNorm1d(512), nn.Dropout(0.4),\n",
    "            nn.Linear(512, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "\n",
    "        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n",
    "\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a5abb",
   "metadata": {},
   "source": [
    "### Во время обучения сохраняю в \"best_model\" лучшую по accuracy на валидации модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8f1e18ef-ba89-4317-a64f-da55ae4a4ce9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Кол-во парраметров =  1677482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 30/30 [09:48<00:00, 19.63s/it]\n"
     ]
    }
   ],
   "source": [
    "accuracy_memory = [0]\n",
    "my_net = my_net()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = my_net.to(device)\n",
    "best_model = model\n",
    "\n",
    "print(\"Кол-во парраметров = \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "\n",
    "lambda1 = lambda epoch: 0.98 ** epoch\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda1)\n",
    "\n",
    "for epoch in tqdm(range(30)):\n",
    "    accuracy_list = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        images = batch[0]\n",
    "        targets = batch[1]\n",
    "        preds = my_net.forward(images.to(device))\n",
    "\n",
    "        loss_batch = loss(preds, targets.to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_batch.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        accuracy_batch = (preds.argmax(dim=1) == targets.to(device)).float().mean()\n",
    "        accuracy_list.append(accuracy_batch.item())\n",
    "\n",
    "    accuracy = (sum(accuracy_list) / len(accuracy_list))\n",
    "    #print(f\"Точность валидации {epoch + 1} эпохи = \", accuracy, \"%\", sep=\"\")\n",
    "    accuracy_list = []\n",
    "\n",
    "    for batch in valid_loader:\n",
    "        with torch.no_grad():\n",
    "            images = batch[0]\n",
    "            targets = batch[1]\n",
    "            preds = my_net.forward(images.to(device))\n",
    "        \n",
    "            accuracy_batch = (preds.argmax(dim=1) == targets.to(device)).float().mean()\n",
    "            accuracy_list.append(accuracy_batch.item())\n",
    "\n",
    "    accuracy = (sum(accuracy_list) / len(accuracy_list))\n",
    "    if accuracy > max(accuracy_memory):\n",
    "        best_model = model\n",
    "    accuracy_memory.append(accuracy)\n",
    "    scheduler.step()\n",
    "    #print(f\"Точность валидации {epoch + 1} эпохи = \", accuracy, \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "40382acb-10bd-4ac9-8866-986d5508c75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9927083333333333"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracy_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3d670460-fdef-4b6e-b571-15c06e986b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad841ba",
   "metadata": {},
   "source": [
    "### Делаю предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4691ea56-04ea-4c26-9ccf-a360a1985b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arr = []\n",
    "model = best_model\n",
    "for i in range(0, len(X_test), batch_size):\n",
    "    with torch.no_grad():\n",
    "        batch = (torch.tensor(X_test[i:i + batch_size])).float()\n",
    "        pred = my_net.forward(batch.to(device))\n",
    "        pred_arr.append(pred.argmax(dim=1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f459436d-26f1-4336-8af1-2041f8656652",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = np.array(pred_arr).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "dc25bc88-254c-4caf-82ae-ebf4c03e6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2f97f8f-a2a5-45ac-95a3-2bdc79d25acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"label\"] = answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1500c7b-3520-46d9-9cfa-287620b1e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df = df_test[\"label\"]\n",
    "answer_df.to_csv(\"answer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d14126-4ca0-448e-89c9-4b0724fb8141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
